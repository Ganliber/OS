# 物理内存管理

> 连续内存分配

[TOC]

## 计算机体系结构

### CPU

```
>>>>>>>> CPU <<<<<<<<
* ALU : 算数逻辑单元
* Cache : 高速缓存
* MMU : 储存管理单元

+-------------------+-----------------+
|        ALU        |                 |
+-------------------+ Logical Control |
|      register     |                 |
+-------------------+-----------------+
|                 Cache               |
+-------------------------------------+
|                  MMU                |
+-------------------------------------+
```



### 内存层次

```
* Processor : 处理器
* Memory : 内存
* External storage : 外存

+-------------------------+
|        Processor        |
|     +-------------+     |
|     |     CPU     |     |
|     +-------------+     |
|     |   L1 Cache  |     |
|     +-------------+     |
|                         |
|   +------------------+  |
|   |     L2 Cache     |  |
|   +------------------+  |
+-------------------------+                  Hardware
             | (高速缓存未命中)                (MMU)
             +
+———————————————————————————————————————————————————————+
           Memory
             | (缺页)                           OS
             +
    External Storage (Virtual Memory)
      
```



### 内存管理

> 要求与希望
>
> 1. 抽象：逻辑地址空间
> 2. 保护：独立地址空间
> 3. 共享：访问相同内存，共享kernel的code
> 4. 虚拟化：更大的地址空间
>
> 通过`MMU`实现两者互相转换
>
> ```
> Logical(virtual) address space
>        |              +
>        +              |
>       Physical address spcae
> ```

* 内存

  > 字节为单位访问，每个字节有自己的物理地址

* 外存

  > 磁盘，扇区编号，每个扇区512字节为最小单位

  

### 内存管理方式

#### OS中采取的内存管理方式

* 重定位`relocation`
  * 跨机器，迁移性，如->基址：偏移地址
* 分段`segmentation`
  * 将内存分成不连续的块，如代码段、数据段、堆栈
* 分页`paging`
  * 便于管理，作为连续地址空间的最小单位
* 虚拟存储`virtual memory`
  * 目前多数系统`linux`采用按需页式虚拟存储

#### 实现高度依赖硬件

* 与计算机存储架构紧密耦合
* MMU（内存管理单元）：处理CPU存储访问请求的硬件





## 地址空间 & 地址生成

###  地址空间定义

* 物理地址空间：硬件支持的地址空间
  * 起始地址 0，直到`MAX sys`

* 逻辑地址空间：在CPU运行的进程看到的地址
  * 起止地址 0，直到`MAX prog`

* 

### 逻辑地址的生成

#### 地址生成时机和限制

> 前两种实现简单，但灵活性不足
>
> 所以我们希望在执行时生成地址

* 编译时
  * 假设起始地址已知
  * 如果起始地址改变，必须重新编译
* 加载时
  * 如编译时起始位置位置，编译器需生成可重定位的代码`relocatable code`
  * 加载时生成绝对地址

* 执行时
  * 执行时代码可移动
  * 需要地址转换（映射）的硬件支持



#### 地址生成过程

1. CPU
   1. ALU：需要逻辑地址的内存内容
   2. MMU：进行逻辑地址和物理地址的转换
   3. CPU控制逻辑：给总线发送地址请求
2. 内存
   1. 发送物理地址的内容给CPU
   2. （或）接收CPU数据到物理地址
3. OS
   1. 建立逻辑地址`LA`和物理地址`PA`的映射



#### 地址生成过程中的地址检查

...



## 连续内存分配

#### 连续内存分配/内存碎片

* 连续内存分配：给进程分配一块不小于指定大小的连续的物理内存区域
* 内存碎片：
  * 空闲内存不能被利用
  * 分类
    * 外部碎片：分配单元**之间**的未被使用内存
    * 内部碎片：分配单元**内部**的未被使用内存，取决于分配单元大小是否要取整

#### 动态分区分配

* 动态分区分配
  * 当程序被加载执行时，分配一个进程指定大小可变的分区（块，内存块）
  * 分区的地址是连续的
* 操作系统需要维护的**数据结构**
  * 当前所有进程的已分配分区
  * 空闲分区 `Empty-blocks`
* 动态分区的分配策略
  * 最先匹配 `First-fit`
  * 最佳匹配 `Best-fit`
  * 最差匹配 `Worst-fit`



#### First Fit Allocation

* 思路

  > 分配n个字节，使用第一个可用空间比n大的空闲块

* 原理 & 实现
  * 空闲分区列表按照**地址顺序**排序
  * 分配时，搜索一个合适分区
  * 释放时，**检查是否可与临近的空闲分区合并**
* 优点
  * 简单
  * 在高地址空间有大块的空闲分区（由于总是从低地址开始查找，会在高地址区域形成一些整块的大片空闲区域）
* 缺点
  * 外部碎片（由于总是切割）
  * 分配大块时较慢：越靠后，搜索开销越大

#### Best Fit Allocation

* 思路

  > 分配n字节区域时，查找并使用不小于n的**最小空闲分区**

* 原理 & 实现

  * 空闲分区列表按照**从小到大**排序
  * 分配时，查找一个合适区域
  * 释放时，查找并且合并临近的空闲分区（如果找到）
    * 注意，是地址临近而不是大小临近

* 优点

  * 大部分分配的尺寸较小时，效果很好
    * 避免大的空闲分区被拆分
    * 可以减小外部碎片的大小
    * 相对简单

* 缺点

  * 外部碎片（会比较多）
  * 释放分区较慢
  * 容易产生很多无用的小碎片





#### Worst Fit Allocation

* 思路

  > 分配n字节区域时，查找并使用不小于n的**最大空闲分区**

* 原理 & 实现

  * 空闲分区列表按照**从大到小**排序
  * 分配时，选最大的分区
  * 释放时，检查是否可与临近的空闲分区合并进行可能的合并，并调整空闲分区列表的顺序
    * 注意，是地址临近而不是大小临近

* 优点

  * 中等大小的分配较多时，效果很好
  * 避免出现太多小碎片

* 缺点
  * 外部碎片
  * 释放分区较慢（要重新排序和搜索）
  * 容易破坏大的空闲分区，因此后续难以分配大的分区



### 碎片整理

* 碎片整理：通过调整进程占用的分区位置来减少或避免分区碎片

* 碎片紧凑：

  * 定义：通过移动分配给进程的内存分区，以合并**外部碎片**

  * 碎片紧凑的条件：所有的应用程序都可以动态重定位
    * 考虑开销
    * 移动时机：处于**等待状态**的进程移动

* 分区对换`Swapping in/out`

  * 通过**抢占**并**回收**处于**等待状态**进程的分区，以增大可用内存空间

    * waiting process 可以先交换到外存中，等到进程就绪后再交换回内存中

      ```
      就绪队列       ---> 就绪 ---> 运行 --->
                          +          |
                          |          +
      等待队列         对换等待 <--- 等待 
                          就绪  <---  *
      
      * 即由等待到就绪可以中间插入 `对换等待` 的环节以增大可用的内
      
         +-------------------+
         |                   |
         +                   | (1) Direct
      * 就绪 ---> 运行 ---> 等待
         +                   | (2) Swapping in/out
         |                   |
         +-`swapping in/out`-+
      ```

  * **早期**操作系统（内存紧张）有专门的`对换分区`，通过对换实现多进程交替运行，但交替的开销很大

## 伙伴系统

> Buddy System
>
> 一种基于连续内存分配的实例

* 整个可分配分区大小为`2^u`
* 需要的分区大小为`2^(u-1) < s <= 2^u`，吧整个块分配给该进程
* 当两个块的和不是`2^u`的形式时，无法合并

#### 伙伴系统的实现

* 数据结构
  * 空闲块按照**大小**和**起始地址**组织成二维数组（第一维度是空闲块的大小，由小到大排列；相同大小空闲块按照地址排序）
  * 初始状态：只有一个大小为`2^u`的空闲块
* 分配过程（先定块，后考虑是否对块进行分割）
  * （定块）由小到大在空闲块中找最小的可用空闲块
  * （分割）如果空闲块过大，对可用空闲块进行二等分，直到得到合适的空闲块。

* 释放过程

  * 把**释放的块**放入空闲块数组
  * 合并**满足合并条件**的空闲块

* 合并条件

  * **大小相同**（相邻两块必须大小相同，才能合并后依然保持是`2^i`的形式）

  * **地址相邻**

  * 可以把内存条看做完全二叉树的结构，不属于同一分支的不能合并`5 和 6 不能合并`：

    **起始地址较小的块的起始地址必须是`2^(i+1)`的倍数**（即5和6大小均为256K`u^i`，但此时`2^(i+1)==512K`，5的起始地址并非512K的倍数（但0可以是512的倍数），因此5,6不能合并）

    > 如下所示，如果1是整个1M内存的话，那么每行每块的大小分别为
    >
    > 第一行：1024K	第二行：512K	第三行：256K	第四行：128K
    >
    > 2：[0, 512K)
    >
    > 3：[512K, 1024K)
    >
    > 5：[256K, 512K)
    >
    > 8：[256, 384)

    ```mermaid
    flowchart
     1-->2
     1-->3
     2-->4
     2-->5
     3-->6
     3-->7
    5-->8
    5-->9
    ```

    

#### ucore 中的物理内存管理

> 对物理内存管理的标准接口：`pmm_manager`（定义在`kern/mm/pmm.h`中）

* 结构

  ```C
  // pmm_manager is a physical memory management class. A special pmm manager - XXX_pmm_manager
  // only needs to implement the methods in pmm_manager class, then XXX_pmm_manager can be used
  // by ucore to manage the total physical memory space.
  struct pmm_manager {
    // XXX_pmm_manager's name
    const char *name;
    
    // initialize internal description&management data structure
    // (free block list, number of free block) of XXX_pmm_manager 
    void (*init)(void);  
     
    // setup description&management data structcure according to
    // the initial free physical memory space 
    void (*init_memmap)(struct Page *base, size_t n); 
                                          
    // allocate >=n pages, depend on the allocation algorithm 
    struct Page *(*alloc_pages)(size_t n);
    
    // free >=n pages with "base" addr of Page descriptor structures(memlayout.h)
    void (*free_pages)(struct Page *base, size_t n);
    
    // return the number of free pages 
    size_t (*nr_free_pages)(void);
    
    // check the correctness of XXX_pmm_manager 
    void (*check)(void);                              
  };
  ```





